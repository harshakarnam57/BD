{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1130017, 8)\n",
      "(1444963, 11)\n",
      "(17712, 22)\n",
      "(143258, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Andrew L. Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>Urban Cinefile</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link      critic_name  top_critic  publisher_name  \\\n",
       "0            m/0814255  Andrew L. Urban       False  Urban Cinefile   \n",
       "\n",
       "  review_type review_score review_date  \\\n",
       "0       Fresh          NaN  2010-02-06   \n",
       "\n",
       "                                      review_content  \n",
       "0  A fantasy adventure that fuses Greek mythology...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>originalScore</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>scoreSentiment</th>\n",
       "      <th>reviewUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beavers</td>\n",
       "      <td>1145982</td>\n",
       "      <td>2003-05-23</td>\n",
       "      <td>Ivan M. Lincoln</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5/4</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Deseret News (Salt Lake City)</td>\n",
       "      <td>Timed to be just long enough for most youngste...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.deseretnews.com/article/700003233/B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  reviewId creationDate       criticName  isTopCritic originalScore  \\\n",
       "0  beavers   1145982   2003-05-23  Ivan M. Lincoln        False         3.5/4   \n",
       "\n",
       "  reviewState                 publicatioName  \\\n",
       "0       fresh  Deseret News (Salt Lake City)   \n",
       "\n",
       "                                          reviewText scoreSentiment  \\\n",
       "0  Timed to be just long enough for most youngste...       POSITIVE   \n",
       "\n",
       "                                           reviewUrl  \n",
       "0  http://www.deseretnews.com/article/700003233/B...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_info</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>authors</th>\n",
       "      <th>actors</th>\n",
       "      <th>original_release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>production_company</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_status</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Always trouble-prone, the life of teenager Per...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>Craig Titley, Chris Columbus, Rick Riordan</td>\n",
       "      <td>Logan Lerman, Brandon T. Jackson, Alexandra Da...</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>...</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link                                        movie_title  \\\n",
       "0            m/0814255  Percy Jackson & the Olympians: The Lightning T...   \n",
       "\n",
       "                                          movie_info  \\\n",
       "0  Always trouble-prone, the life of teenager Per...   \n",
       "\n",
       "                                   critics_consensus content_rating  \\\n",
       "0  Though it may seem like just another Harry Pot...             PG   \n",
       "\n",
       "                                              genres       directors  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...  Chris Columbus   \n",
       "\n",
       "                                      authors  \\\n",
       "0  Craig Titley, Chris Columbus, Rick Riordan   \n",
       "\n",
       "                                              actors original_release_date  \\\n",
       "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...            2010-02-12   \n",
       "\n",
       "   ... production_company  tomatometer_status tomatometer_rating  \\\n",
       "0  ...   20th Century Fox              Rotten               49.0   \n",
       "\n",
       "  tomatometer_count  audience_status  audience_rating audience_count  \\\n",
       "0             149.0          Spilled             53.0       254421.0   \n",
       "\n",
       "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "0                             43                               73   \n",
       "\n",
       "   tomatometer_rotten_critics_count  \n",
       "0                                76  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>audienceScore</th>\n",
       "      <th>tomatoMeter</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratingContents</th>\n",
       "      <th>releaseDateTheaters</th>\n",
       "      <th>releaseDateStreaming</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genre</th>\n",
       "      <th>originalLanguage</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>boxOffice</th>\n",
       "      <th>distributor</th>\n",
       "      <th>soundMix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space-zombie-bingo</td>\n",
       "      <td>Space Zombie Bingo!</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Comedy, Horror, Sci-fi</td>\n",
       "      <td>English</td>\n",
       "      <td>George Ormrod</td>\n",
       "      <td>George Ormrod,John Sabotta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                title  audienceScore  tomatoMeter rating  \\\n",
       "0  space-zombie-bingo  Space Zombie Bingo!           50.0          NaN    NaN   \n",
       "\n",
       "  ratingContents releaseDateTheaters releaseDateStreaming  runtimeMinutes  \\\n",
       "0            NaN                 NaN           2018-08-25            75.0   \n",
       "\n",
       "                    genre originalLanguage       director  \\\n",
       "0  Comedy, Horror, Sci-fi          English  George Ormrod   \n",
       "\n",
       "                       writer boxOffice distributor soundMix  \n",
       "0  George Ormrod,John Sabotta       NaN         NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load review datasets\n",
    "dfr1 = pd.read_csv('movie/rotten_tomatoes_critic_reviews.csv')\n",
    "dfr2 = pd.read_csv('review/rotten_tomatoes_movie_reviews.csv')\n",
    "# Load movie datasets\n",
    "dfm1 = pd.read_csv('movie/rotten_tomatoes_movies.csv')\n",
    "dfm2 = pd.read_csv('review/rotten_tomatoes_movies.csv')\n",
    "# Check the shape of the datasets\n",
    "print(dfr1.shape)\n",
    "print(dfr2.shape)\n",
    "print(dfm1.shape)\n",
    "print(dfm2.shape)\n",
    "# Display the first row of each dataset\n",
    "for i in (dfr1, dfr2, dfm1, dfm2):\n",
    "    display(i.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "dfr1.rename(columns={'rotten_tomatoes_link':'id'}, inplace=True)\n",
    "dfm1.rename(columns={'rotten_tomatoes_link':'id'},  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFR1 NULL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "critic_name        18529\n",
       "top_critic             0\n",
       "publisher_name         0\n",
       "review_type            0\n",
       "review_score      305936\n",
       "review_date            0\n",
       "review_content     65806\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFR2 NULL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "reviewId               0\n",
       "review_date            0\n",
       "critic_name            0\n",
       "top_critic             0\n",
       "review_score      435218\n",
       "review_type            0\n",
       "publisher_name         0\n",
       "review_content     69225\n",
       "scoreSentiment         0\n",
       "reviewUrl         210925\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Andrew L. Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>Urban Cinefile</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Louise Keller</td>\n",
       "      <td>False</td>\n",
       "      <td>Urban Cinefile</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      critic_name  top_critic  publisher_name review_type  \\\n",
       "0  m/0814255  Andrew L. Urban       False  Urban Cinefile       Fresh   \n",
       "1  m/0814255    Louise Keller       False  Urban Cinefile       Fresh   \n",
       "\n",
       "  review_score review_date                                     review_content  \n",
       "0          NaN  2010-02-06  A fantasy adventure that fuses Greek mythology...  \n",
       "1          NaN  2010-02-06  Uma Thurman as Medusa, the gorgon with a coiff...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1130017 entries, 0 to 1130016\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   id              1130017 non-null  object\n",
      " 1   critic_name     1111488 non-null  object\n",
      " 2   top_critic      1130017 non-null  bool  \n",
      " 3   publisher_name  1130017 non-null  object\n",
      " 4   review_type     1130017 non-null  object\n",
      " 5   review_score    824081 non-null   object\n",
      " 6   review_date     1130017 non-null  object\n",
      " 7   review_content  1064211 non-null  object\n",
      "dtypes: bool(1), object(7)\n",
      "memory usage: 61.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_info</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>authors</th>\n",
       "      <th>actors</th>\n",
       "      <th>original_release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>production_company</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_status</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Always trouble-prone, the life of teenager Per...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>Craig Titley, Chris Columbus, Rick Riordan</td>\n",
       "      <td>Logan Lerman, Brandon T. Jackson, Alexandra Da...</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>...</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0878835</td>\n",
       "      <td>Please Give</td>\n",
       "      <td>Kate (Catherine Keener) and her husband Alex (...</td>\n",
       "      <td>Nicole Holofcener's newest might seem slight i...</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Catherine Keener, Amanda Peet, Oliver Platt, R...</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>Sony Pictures Classics</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>87.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Upright</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11574.0</td>\n",
       "      <td>44</td>\n",
       "      <td>123</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        movie_title  \\\n",
       "0  m/0814255  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1  m/0878835                                        Please Give   \n",
       "\n",
       "                                          movie_info  \\\n",
       "0  Always trouble-prone, the life of teenager Per...   \n",
       "1  Kate (Catherine Keener) and her husband Alex (...   \n",
       "\n",
       "                                   critics_consensus content_rating  \\\n",
       "0  Though it may seem like just another Harry Pot...             PG   \n",
       "1  Nicole Holofcener's newest might seem slight i...              R   \n",
       "\n",
       "                                              genres          directors  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
       "1                                             Comedy  Nicole Holofcener   \n",
       "\n",
       "                                      authors  \\\n",
       "0  Craig Titley, Chris Columbus, Rick Riordan   \n",
       "1                           Nicole Holofcener   \n",
       "\n",
       "                                              actors original_release_date  \\\n",
       "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...            2010-02-12   \n",
       "1  Catherine Keener, Amanda Peet, Oliver Platt, R...            2010-04-30   \n",
       "\n",
       "   ...      production_company  tomatometer_status tomatometer_rating  \\\n",
       "0  ...        20th Century Fox              Rotten               49.0   \n",
       "1  ...  Sony Pictures Classics     Certified-Fresh               87.0   \n",
       "\n",
       "  tomatometer_count  audience_status  audience_rating audience_count  \\\n",
       "0             149.0          Spilled             53.0       254421.0   \n",
       "1             142.0          Upright             64.0        11574.0   \n",
       "\n",
       "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "0                             43                               73   \n",
       "1                             44                              123   \n",
       "\n",
       "   tomatometer_rotten_critics_count  \n",
       "0                                76  \n",
       "1                                19  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17712 entries, 0 to 17711\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   id                                17712 non-null  object \n",
      " 1   movie_title                       17712 non-null  object \n",
      " 2   movie_info                        17391 non-null  object \n",
      " 3   critics_consensus                 9134 non-null   object \n",
      " 4   content_rating                    17712 non-null  object \n",
      " 5   genres                            17693 non-null  object \n",
      " 6   directors                         17518 non-null  object \n",
      " 7   authors                           16170 non-null  object \n",
      " 8   actors                            17360 non-null  object \n",
      " 9   original_release_date             16546 non-null  object \n",
      " 10  streaming_release_date            17328 non-null  object \n",
      " 11  runtime                           17398 non-null  float64\n",
      " 12  production_company                17213 non-null  object \n",
      " 13  tomatometer_status                17668 non-null  object \n",
      " 14  tomatometer_rating                17668 non-null  float64\n",
      " 15  tomatometer_count                 17668 non-null  float64\n",
      " 16  audience_status                   17264 non-null  object \n",
      " 17  audience_rating                   17416 non-null  float64\n",
      " 18  audience_count                    17415 non-null  float64\n",
      " 19  tomatometer_top_critics_count     17712 non-null  int64  \n",
      " 20  tomatometer_fresh_critics_count   17712 non-null  int64  \n",
      " 21  tomatometer_rotten_critics_count  17712 non-null  int64  \n",
      "dtypes: float64(5), int64(3), object(14)\n",
      "memory usage: 3.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_type</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beavers</td>\n",
       "      <td>2003-05-23</td>\n",
       "      <td>Ivan M. Lincoln</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5/4</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Deseret News (Salt Lake City)</td>\n",
       "      <td>Timed to be just long enough for most youngste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood_mask</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>The Foywonder</td>\n",
       "      <td>False</td>\n",
       "      <td>1/5</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Dread Central</td>\n",
       "      <td>It doesn't matter if a movie costs 300 million...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id review_date      critic_name  top_critic review_score  \\\n",
       "0     beavers  2003-05-23  Ivan M. Lincoln       False        3.5/4   \n",
       "1  blood_mask  2007-06-02    The Foywonder       False          1/5   \n",
       "\n",
       "  review_type                 publisher_name  \\\n",
       "0       fresh  Deseret News (Salt Lake City)   \n",
       "1      rotten                  Dread Central   \n",
       "\n",
       "                                      review_content  \n",
       "0  Timed to be just long enough for most youngste...  \n",
       "1  It doesn't matter if a movie costs 300 million...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444963 entries, 0 to 1444962\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   id              1444963 non-null  object\n",
      " 1   review_date     1444963 non-null  object\n",
      " 2   critic_name     1444963 non-null  object\n",
      " 3   top_critic      1444963 non-null  bool  \n",
      " 4   review_score    1009745 non-null  object\n",
      " 5   review_type     1444963 non-null  object\n",
      " 6   publisher_name  1444963 non-null  object\n",
      " 7   review_content  1375738 non-null  object\n",
      "dtypes: bool(1), object(7)\n",
      "memory usage: 78.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>audienceScore</th>\n",
       "      <th>tomatoMeter</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratingContents</th>\n",
       "      <th>releaseDateTheaters</th>\n",
       "      <th>releaseDateStreaming</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genre</th>\n",
       "      <th>originalLanguage</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>boxOffice</th>\n",
       "      <th>distributor</th>\n",
       "      <th>soundMix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space-zombie-bingo</td>\n",
       "      <td>Space Zombie Bingo!</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Comedy, Horror, Sci-fi</td>\n",
       "      <td>English</td>\n",
       "      <td>George Ormrod</td>\n",
       "      <td>George Ormrod,John Sabotta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_green_grass</td>\n",
       "      <td>The Green Grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>English</td>\n",
       "      <td>Tiffany Edwards</td>\n",
       "      <td>Tiffany Edwards</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          movie_title  audienceScore  tomatoMeter rating  \\\n",
       "0  space-zombie-bingo  Space Zombie Bingo!           50.0          NaN    NaN   \n",
       "1     the_green_grass      The Green Grass            NaN          NaN    NaN   \n",
       "\n",
       "  ratingContents releaseDateTheaters releaseDateStreaming  runtimeMinutes  \\\n",
       "0            NaN                 NaN           2018-08-25            75.0   \n",
       "1            NaN                 NaN           2020-02-11           114.0   \n",
       "\n",
       "                    genre originalLanguage         director  \\\n",
       "0  Comedy, Horror, Sci-fi          English    George Ormrod   \n",
       "1                   Drama          English  Tiffany Edwards   \n",
       "\n",
       "                       writer boxOffice distributor soundMix  \n",
       "0  George Ormrod,John Sabotta       NaN         NaN      NaN  \n",
       "1             Tiffany Edwards       NaN         NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143258 entries, 0 to 143257\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    143258 non-null  object \n",
      " 1   movie_title           142891 non-null  object \n",
      " 2   audienceScore         73248 non-null   float64\n",
      " 3   tomatoMeter           33877 non-null   float64\n",
      " 4   rating                13991 non-null   object \n",
      " 5   ratingContents        13991 non-null   object \n",
      " 6   releaseDateTheaters   30773 non-null   object \n",
      " 7   releaseDateStreaming  79420 non-null   object \n",
      " 8   runtimeMinutes        129431 non-null  float64\n",
      " 9   genre                 132175 non-null  object \n",
      " 10  originalLanguage      129400 non-null  object \n",
      " 11  director              139041 non-null  object \n",
      " 12  writer                90116 non-null   object \n",
      " 13  boxOffice             14743 non-null   object \n",
      " 14  distributor           23001 non-null   object \n",
      " 15  soundMix              15917 non-null   object \n",
      "dtypes: float64(3), object(13)\n",
      "memory usage: 17.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfr2.rename(columns={'criticName': 'critic_name', 'creationDate':'review_date', 'isTopCritic':'top_critic', 'publicatioName': 'publisher_name',\n",
    "                      'reviewText': 'review_content','originalScore':'review_score', 'reviewState': 'review_type'}, inplace=True)\n",
    "dfm2.rename(columns={'title':'movie_title'}, inplace=True)\n",
    "# Check for missing values\n",
    "print('DFR1 NULL')\n",
    "display(dfr1.isnull().sum())\n",
    "print('DFR2 NULL')\n",
    "display(dfr2.isnull().sum())\n",
    "# Drop unnecessary columns\n",
    "dfr2.drop(columns=['reviewId','scoreSentiment','reviewUrl' ], inplace=True)\n",
    "# Display the first two rows and data information\n",
    "for i in dfr1, dfm1, dfr2, dfm2:\n",
    "    display(i.head(2))\n",
    "    display(i.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.functions import regexp_replace, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+----------+------------+-----------+--------------------+--------------------+--------------------+\n",
      "|        id|review_date|    critic_name|top_critic|review_score|review_type|      publisher_name|      review_content|              tokens|\n",
      "+----------+-----------+---------------+----------+------------+-----------+--------------------+--------------------+--------------------+\n",
      "|   beavers| 2003-05-23|Ivan M. Lincoln|     false|       3.5/4|      fresh|Deseret News (Sal...|Timed to be just ...|[timed, to, be, j...|\n",
      "|blood_mask| 2007-06-02|  The Foywonder|     false|         1/5|     rotten|       Dread Central|It doesnt matter ...|[it, doesn't, mat...|\n",
      "+----------+-----------+---------------+----------+------------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"New_NLP\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "# Create Spark DataFrames from pandas DataFrames\n",
    "sp_dfr1 = spark.createDataFrame(dfr1)\n",
    "sp_dfr2 = spark.createDataFrame(dfr2)\n",
    "sp_dfm1 = spark.createDataFrame(dfm1)\n",
    "sp_dfm2 = spark.createDataFrame(dfm2)\n",
    "# Drop rows with missing values\n",
    "sp_dfr1 = sp_dfr1.na.drop()\n",
    "sp_dfr2 = sp_dfr2.na.drop()\n",
    "# Tokenize the review content\n",
    "tokenizer = Tokenizer(inputCol=\"review_content\", outputCol=\"tokens\")\n",
    "sp_dfr1 = tokenizer.transform(sp_dfr1)\n",
    "sp_dfr2 = tokenizer.transform(sp_dfr2)\n",
    "# Remove non-alphanumeric characters from review content\n",
    "sp_dfr1 = sp_dfr1.withColumn(\"review_content\", regexp_replace(col(\"review_content\"), \"[^a-zA-Z0-9\\s,;]\", \"\"))\n",
    "sp_dfr2 = sp_dfr2.withColumn(\"review_content\", regexp_replace(col(\"review_content\"), \"[^a-zA-Z0-9\\s,;]\", \"\"))\n",
    "# Display a sample of the transformed data\n",
    "sp_dfr2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join to merge review data with movie data\n",
    "reviews1 = sp_dfr1.join(sp_dfm1, \"id\", \"inner\")\n",
    "reviews2 = sp_dfr2.join(sp_dfm2, \"id\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o381.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 6.0 failed 1 times, most recent failure: Lost task 3.0 in stage 6.0 (TID 13) (DESKTOP-GM42297 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m reviews1\u001b[38;5;241m.\u001b[39munion(reviews2)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Display a sample of the merged DataFrame\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Save the merged data locally (this will be uploaded to HDFS)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mcoalesce(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewsjoined.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\sql\\dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\sql\\dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o381.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 6.0 failed 1 times, most recent failure: Lost task 3.0 in stage 6.0 (TID 13) (DESKTOP-GM42297 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n"
     ]
    }
   ],
   "source": [
    "# Free up memory by unpersisting Spark DataFrames\n",
    "sp_dfr1.unpersist()\n",
    "sp_dfr2.unpersist()\n",
    "sp_dfm1.unpersist()\n",
    "sp_dfm2.unpersist()\n",
    "# Select only the necessary columns\n",
    "reviews1 = reviews1.select('movie_title', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content' )\n",
    "reviews2 = reviews2.select('movie_title', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content' )\n",
    "# Drop rows with missing values\n",
    "reviews1 = reviews1.na.drop()\n",
    "reviews2 = reviews2.na.drop()\n",
    "# Combine both review DataFrames into one for further analysis\n",
    "merged_df = reviews1.union(reviews2)\n",
    "# Display a sample of the merged DataFrame\n",
    "merged_df.show(1)\n",
    "# Save the merged data locally (this will be uploaded to HDFS)\n",
    "merged_df.coalesce(1).write.csv('reviewsjoined.csv', header=True)\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the integrated data\n",
    "df = pd.read_csv('reviewsjoined.csv/part-00000-6621b1b4-081e-4862-8892-3c1af2800b1e-c000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "# Sample data for parallel preprocessing\n",
    "sample_df = df.sample(500000)\n",
    "sample_df['review_content'] = sample_df['review_content'].astype(str)\n",
    "# Define functions for preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "    processed_text = ' '.join(lemmatized_words)\n",
    "    return processed_text\n",
    "def parallel_preprocess(data):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        processed_data = list(executor.map(preprocess_text, data))\n",
    "    return processed_data\n",
    "# Parallel preprocessing\n",
    "sample_df['review_content'] = parallel_preprocess(sample_df['review_content'])\n",
    "# Remove commas from review content\n",
    "sample_df['review_content'] = sample_df['review_content'].apply(lambda x: x.replace(\",\", \"\"))\n",
    "# Remove special characters from movie titles\n",
    "sample_df['movie_title'] = sample_df['movie_title'].apply(lambda x: ''.join(e for e in x if e.isalnum() or e.isspace()))\n",
    "# Display the preprocessed sample data\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and special characters from review content and movie titles\n",
    "df['review_content'] = df['review_content'].apply(lambda x: x.replace(\",\", \"\"))\n",
    "df['movie_title'] = df['movie_title'].apply(lambda x: ''.join(e for e in x if e.isalnum() or e.isspace()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and preprocessed data for Hadoop\n",
    "df.to_csv('big_movies.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
